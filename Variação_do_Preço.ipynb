{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "## Notebook para cria\u00e7\u00e3o da base com os valores m\u00ednimos, m\u00e1ximos e m\u00e9dia por:\n- SKU;\n- Estado (Regional);\n- Lojista;\n\n#### A ideia \u00e9 dar uma vis\u00e3o para o lojista dos pre\u00e7os praticados nacionalmente e por regi\u00e3o (estado) "}, {"metadata": {}, "cell_type": "markdown", "source": "## Iniciando o Notebook\n#### Inicializa\u00e7\u00e3o da sess\u00e3o do notebook importando a biblioteca do projeto"}, {"metadata": {}, "cell_type": "code", "source": "# @hidden_cell\n# The project token is an authorization token that is used to access project resources like data sources, connections, and used by platform APIs.\nfrom project_lib import Project\nproject = Project(project_id='de02faf2-fbe4-466f-b8cd-44296f096a9d', project_access_token='p-25957a2b4ca812c11c01435cf691ea3068358702')\npc = project.project_context\n\nprojectSPK = Project(spark.sparkContext, 'de02faf2-fbe4-466f-b8cd-44296f096a9d', 'p-25957a2b4ca812c11c01435cf691ea3068358702')\npcSPK = project.project_context", "execution_count": 1, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20210530023517-0001\nKERNEL_ID = 4c430993-2f40-48d3-9cb3-d386d53c0961\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**Importando algumas bibliotecas utilizadas no projeto**"}, {"metadata": {}, "cell_type": "code", "source": "import sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**Incluir os par\u00e2metros de conex\u00e3o para usar os arquivos de dados com PYSPARK**"}, {"metadata": {}, "cell_type": "code", "source": "import ibmos2spark, os\nfrom pyspark.sql import functions as func\n\n# @hidden_cell\n\nif os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n    endpoint_f35d990ae08e4675b679f0f50769655c = 'https://s3-api.us-geo.objectstorage.softlayer.net'\nelse:\n    endpoint_f35d990ae08e4675b679f0f50769655c = 'https://s3-api.us-geo.objectstorage.service.networklayer.com'\n\ncredentials = {\n    'endpoint': endpoint_f35d990ae08e4675b679f0f50769655c,\n    'service_id': 'iam-ServiceId-f8ddc357-a261-42a2-a6f2-44ac38d6cc50',\n    'iam_service_endpoint': 'https://iam.cloud.ibm.com/oidc/token',\n    'api_key': '5y97tXSIMk-o11IIlG-qhORjxg4zQ6yFprxqB54ntyX9'\n}\n\nconfiguration_name = 'os_f35d990ae08e4675b679f0f50769655c_configs'\ncos = ibmos2spark.CloudObjectStorage(sc, credentials, configuration_name, 'bluemix_cos')\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\ndfSKULogista = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('skulojista.csv', 'projetoviagrupo6-donotdelete-pr-ehmgbn0j3d7dfc'))\n#dfSKULogista.take(5)\n\ndfLojista = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('lojista.csv', 'projetoviagrupo6-donotdelete-pr-ehmgbn0j3d7dfc'))\n#dfLojista.take(5)", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**Cria as tabelas tempor\u00e1rias para utiliza\u00e7\u00e3o com comandos SQL no spark**"}, {"metadata": {}, "cell_type": "code", "source": "dfSKULogista.createOrReplaceTempView(\"SKULojista\")\ndfLojista.createOrReplaceTempView(\"Lojista\")", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## An\u00e1lise exporat\u00f3ria dos dados"}, {"metadata": {}, "cell_type": "markdown", "source": "**Analise da tabela SKULOJISTA**\nAnalise do campo flagativa para identificar se este campo indica se o produto est\u00e1 ativo ou n\u00e3o\nEstou usando o campo idskureferencia que \u00e9 o SKU da VIA, pegando somente cadastros que estejam com este campo preenchido "}, {"metadata": {}, "cell_type": "code", "source": "#identificando o dom\u00ednio do campo flagativa -> s\u00f3 tem 0 e 1 (entede-se que 0 \u00e9 ativa e 1 n\u00e3o ativa)\nspark.sql(\"SELECT distinct flagativa\\\n             FROM SKULojista \\\n             where idskureferencia is not null\\\n             ;\").show()", "execution_count": 4, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+\n|flagativa|\n+---------+\n|        0|\n|        1|\n+---------+\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**Identificando o dom\u00ednio dos campos flagativa e flagskusaldodisponivel**\nPara ver a rela\u00e7\u00e3o entre os dois e ver se o campo flagativa quando for 0 significa que \u00e9 ativo mesmo"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT distinct flagativa, flagskusaldodisponivel\\\n             FROM SKULojista \\\n             where idskureferencia is not null\\\n             ;\").show()", "execution_count": 5, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+----------------------+\n|flagativa|flagskusaldodisponivel|\n+---------+----------------------+\n|        1|                     1|\n|        0|                     1|\n|        0|                     0|\n|        1|                     0|\n+---------+----------------------+\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**diante das an\u00e1lises acima foi poss\u00edvel observar que o campo flagativa e flagskusaldodisponivel n\u00e3o d\u00e1 para ser usado \nDiante disto vamos analisar apenas um lojista com produtos que possui precovenda > 0**"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT idlojista, idsku, idskureferencia, precoanterior, precovenda\\\n             FROM SKULojista \\\n             where idlojista = 14738\\\n             and idskureferencia is not null\\\n             and precovenda > 0\\\n             ;\").show()", "execution_count": 43, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+----------+---------------+-------------+----------+\n|idlojista|     idsku|idskureferencia|precoanterior|precovenda|\n+---------+----------+---------------+-------------+----------+\n|    14738|      2928|        3168410|      2099.00|   3010.90|\n|    14738|    273538|        3243416|       166.17|    137.90|\n|    14738|   1766101|        3309575|       419.90|    450.90|\n|    14738|   3986943|        4211616|      1069.00|    879.00|\n|    14738|   6054828|        6054828|       143.50|    188.90|\n|    14738|   7435907|        7435907|       420.90|    623.90|\n|    14738|   7435929|        7435929|       157.90|    261.90|\n|    14738|   9600906|       10035626|       259.90|    220.90|\n|    14738|   9600943|       10035622|       259.90|    220.90|\n|    14738|  11505985|       11505985|       592.30|    570.50|\n|    14738|  11549428|       11607833|         0.00|    837.40|\n|    14738|  11689365|       12030946|      5199.00|   7314.90|\n|    14738|  11700710|       11763185|       899.91|    939.90|\n|    14738|  13239282|       13239282|      1669.00|   2838.90|\n|    14738|  13791186|       13791186|      2499.00|   3367.90|\n|    14738|  14826398|       14826398|         0.00|    207.00|\n|    14738|1500773264|     1500773264|         0.00|    287.90|\n|    14738|1500843881|     1500843881|         0.00|    311.00|\n|    14738|1501961512|     1501961512|         0.00|    499.00|\n|    14738|1503139175|     1503139175|         0.00|    986.90|\n+---------+----------+---------------+-------------+----------+\nonly showing top 20 rows\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**Analise da tabela LOJISTA**\nIdentifiquei que possuimos mais de um registro para um lojista nesta tabela,ex. idlojista = 14738\nidentifiquei que temos o dom\u00ednio 0 e 1 tb para o campo flagativa"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT distinct flagativa\\\n             FROM Lojista \\\n             ;\").show()", "execution_count": 6, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+\n|flagativa|\n+---------+\n|        0|\n|        1|\n+---------+\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**diante desta query podemos observar que o campo flagativa = 1 significa que o seller est\u00e1 ativo**"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT distinct flagativa\\\n             FROM Lojista \\\n             where idlojista = 14738\\\n             ;\").show()", "execution_count": 7, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+\n|flagativa|\n+---------+\n|        1|\n+---------+\n\n"}]}, {"metadata": {}, "cell_type": "code", "source": "# com essa query \u00e9 poss\u00edvel identificar que um seller possui mais de 1 registro\nspark.sql(\"SELECT *\\\n             FROM Lojista \\\n             where idlojista = 14738\\\n             ;\").show()", "execution_count": 8, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+---------+------------------+-------------+-------------------+-----------------+------+--------------------+------------+----------+--------------------+-----------+-------------------+--------------------+-----------+--------------------+-----------+----------+\n|idlojista|flagativa|flaglojistadefault|classificacao|porcentagempositivo|quantidadereviews|estado|flagrestricaovendapj|retiroemloja|lojistagpa|lojistainternacional|idgrupoitem|    datadesativacao|     dataatualizacao|idcompanhia|            idseller|idsubseller|idbandeira|\n+---------+---------+------------------+-------------+-------------------+-----------------+------+--------------------+------------+----------+--------------------+-----------+-------------------+--------------------+-----------+--------------------+-----------+----------+\n|    14738|        1|                 0|            3|                 72|             1679|    PR|                   1|        null|      null|                null|       1000|               null|2019-03-29 17:00:...|       null|bcffabb4-71bd-4e5...|  700007507|        49|\n|    14738|        1|                 0|            3|                 67|              987|    PR|                   1|        null|      null|                null|       1000|               null|2019-03-29 16:59:...|       null|90fdcbdd-49ae-4b3...|  700011294|       343|\n|    14738|        1|                 0|            3|                 73|             2415|    PR|                   1|        null|      null|                null|       1000|2017-03-29 12:19:51|2019-03-29 16:58:...|       null|f5619066-5eca-404...|  700003719|         7|\n+---------+---------+------------------+-------------+-------------------+-----------------+------+--------------------+------------+----------+--------------------+-----------+-------------------+--------------------+-----------+--------------------+-----------+----------+\n\n"}]}, {"metadata": {}, "cell_type": "code", "source": "# obtendo apenas 1 registro\nspark.sql(\"SELECT distinct idlojista, estado\\\n             FROM Lojista \\\n             where idlojista = 14738\\\n             ;\").show()", "execution_count": 9, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+------+\n|idlojista|estado|\n+---------+------+\n|    14738|    PR|\n+---------+------+\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Depois das an\u00e1lises, foi poss\u00edvel identificar que seria ncess\u00e1rio criar uma tabela \u00fanica com pre\u00e7o e estado, para facilitar as pr\u00f3ximas an\u00e1lises"}, {"metadata": {}, "cell_type": "code", "source": "#Criando uma tabela \u00fanica para facitar as an\u00e1lises\ndfSKUs = spark.sql(\"SELECT distinct SK.idlojista, LJ.estado, SK.idsku, SK.idskureferencia\\\n                      ,CAST(SK.precoanterior AS DECIMAL(15, 2)) as precoanterior, CAST(SK.precovenda AS DECIMAL(15, 2)) precovenda\\\n             FROM SKULojista SK, Lojista LJ\\\n             where SK.idskureferencia is not null\\\n               and SK.precovenda > 0\\\n               and SK.idlojista = LJ.idlojista\\\n               ;\")", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dfSKUs.createOrReplaceTempView(\"SKUS\")", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**Analisando os dados criados**"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT *\\\n             FROM SKUS \\\n             where idskureferencia = 8303336\\\n             ;\").show()", "execution_count": 8, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+------+-----+---------------+-------------+----------+\n|idlojista|estado|idsku|idskureferencia|precoanterior|precovenda|\n+---------+------+-----+---------------+-------------+----------+\n|    33259|    SP| 4639|        8303336|       669.00|    699.00|\n|    12793|    SP| 4639|        8303336|       669.00|    699.00|\n|    31133|    SP| 4639|        8303336|       669.00|    499.00|\n|    33237|    PB| 4639|        8303336|       669.00|    699.00|\n|    33223|    SP| 4639|        8303336|       669.00|    699.00|\n|    33261|    SP| 4639|        8303336|       669.00|    699.00|\n|    33229|    PE| 4639|        8303336|       669.00|    699.00|\n|    33225|    PE| 4639|        8303336|       669.00|    699.00|\n|    33263|    SP| 4639|        8303336|       669.00|    699.00|\n|    33233|    PE| 4639|        8303336|       669.00|    699.00|\n|    33245|    BA| 4639|        8303336|       669.00|    699.00|\n|    33277|    PE| 4639|        8303336|       669.00|    699.00|\n|    33213|    SP| 4639|        8303336|       669.00|    699.00|\n|    33239|    SP| 4639|        8303336|       669.00|    699.00|\n|    33216|    SP| 4639|        8303336|       669.00|    699.00|\n|    31141|    SP| 4639|        8303336|       669.00|  20000.00|\n|    33257|    SP| 4639|        8303336|       669.00|    699.00|\n|    33272|    AL| 4639|        8303336|       669.00|    699.00|\n|    33273|    RS| 4639|        8303336|       669.00|    699.00|\n|    33274|    SP| 4639|        8303336|       669.00|    699.00|\n+---------+------+-----+---------------+-------------+----------+\nonly showing top 20 rows\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**Analisando os tipos de dados que foram criados**"}, {"metadata": {}, "cell_type": "code", "source": "dfSKUs.describe()", "execution_count": 9, "outputs": [{"data": {"text/plain": "DataFrame[summary: string, idlojista: string, estado: string, idsku: string, idskureferencia: string, precoanterior: string, precovenda: string]"}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Obtendo os valores m\u00e1ximo, m\u00ednimo e m\u00e9dia baseado na tabela criada, por estado e SKU pois a id\u00e9ia inicial \u00e9 analisar o pre\u00e7o do cat\u00e1logo do seller por regi\u00e3o (estado)"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT idskureferencia \\\n             ,estado\\\n             ,min(precovenda) as minimo\\\n             ,max(precovenda) as maximo\\\n             ,min(precovenda) as media\\\n             FROM SKUS \\\n             group by idskureferencia, estado\\\n             order by maximo desc\\\n             ;\").show()", "execution_count": 10, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+------+--------+---------+--------+\n|idskureferencia|estado|  minimo|   maximo|   media|\n+---------------+------+--------+---------+--------+\n|        3353401|    SP|  589.00|249480.23|  589.00|\n|     1503120785|    SP|99999.00| 99999.00|99999.00|\n|     1503664197|    PR| 2890.00| 94133.37| 2890.00|\n|       11630126|    SP|  178.90| 90000.00|  178.90|\n|     1500015908|    ES|89399.90| 89399.90|89399.90|\n|     1508863399|    PR|86699.90| 86699.90|86699.90|\n|     1500084539|    SP|86654.09| 86654.09|86654.09|\n|       15189020|    RO|79700.00| 79700.00|79700.00|\n|       12413731|    RS|76000.00| 76000.00|76000.00|\n|       12718569|    SP|70581.00| 70581.00|70581.00|\n|     1503019592|    SP|70559.00| 70559.00|70559.00|\n|     1504864479|    SP|70559.00| 70559.00|70559.00|\n|     1506324331|    SC|68333.90| 68333.90|68333.90|\n|        5392997|    PR|66500.00| 66500.00|66500.00|\n|     1511860920|    MG|  583.70| 60000.00|  583.70|\n|     1503019628|    SP|56449.00| 56449.00|56449.00|\n|     1502304748|    GO|55841.89| 55841.89|55841.89|\n|     1501132449|    SC|53947.42| 53947.42|53947.42|\n|        5110408|    SC|53168.90| 53168.90|53168.90|\n|     1504853799|    PR|52850.00| 52850.00|52850.00|\n+---------------+------+--------+---------+--------+\nonly showing top 20 rows\n\n"}]}, {"metadata": {}, "cell_type": "code", "source": "#Criando a tabela tempor\u00e1ria no spark para exportar para arquivo\ndfSKUAgrupado = spark.sql(\"SELECT idskureferencia \\\n             ,estado\\\n             ,min(precovenda) as minimo\\\n             ,max(precovenda) as maximo\\\n             ,min(precovenda) as media\\\n             FROM SKUS \\\n             group by idskureferencia, estado\\\n             order by maximo desc\\\n             ;\")\ndfSKUAgrupado.createOrReplaceTempView(\"SKUAgrupado\")", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## PRE\u00c7O VENDIDO\n#### Nos pr\u00f3ximos passos vamos obter os pre\u00e7os praticados para analisar a vis\u00e3o real do pre\u00e7o \n#### Na sequencia vamos juntar o pre\u00e7o pratica com o pre\u00e7o de cat\u00e1logo pois poder\u00e1 existir situa\u00e7\u00e3o em que um determinado produto n\u00e3o teve venda, \n#### da\u00ed o pre\u00e7o a ser usado para c\u00e1lculo do m\u00e9dio/m\u00ednimo e m\u00e9dia ser\u00e1 o do cat\u00e1logo\n## OBS: UTILIZAMOS 60 dias como par\u00e2metro para buscar os pre\u00e7os\n#### utilizamos 60 dias pois o giro de mercadoria na m\u00e9dia \u00e9 neste intervalo"}, {"metadata": {}, "cell_type": "code", "source": "#Obtendo dados da tabela de compras entregas por sku e criar a tabela tempor\u00e1ria\ndfCompraEntregaSKU = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('compraentregasku.csv', 'projetoviagrupo6-donotdelete-pr-ehmgbn0j3d7dfc'))\ndfCompraEntregaSKU.createOrReplaceTempView(\"compraentregasku\")\ndfCompraEntregaSKU.take(1)", "execution_count": 7, "outputs": [{"data": {"text/plain": "[Row(idcompraentregasku='61380787', idcompraentregaskupai=None, iddescontocomprejunto=None, iddescontobrindecausa=None, idcompraentrega='74476290', idsku='11728496', idestoqueprovavel='7', valorvendaunidadesemdesconto='169.90', valorvendaunidade='169.90', valorcupomnominal='0.00', valorvendaunidademenoscupomnominal='169.90', valorfretecomdesconto='72.60', valorfrete='72.60', flagestoqueimpacto='1', presentemensagem=None, presentede=None, presentepara=None, idskukitsige=None, tipocombosige=None, datacriacaoregistro='2019-06-01 00:15:56.447', valorbogof='0.00', parceirorecomendacao=None, flagajusteoperacional=None, valorfreteoriginalnaorentavel='72.60', statustdca=None, valorst='0.00', sequencial='1', prazogarantiafornecedor='12', tipoestoque='N', valorjurosunitario=None, idskureferencia='11728496', precoiofvalorvenda='0.00', valorcomissao=None, percentualComissao=None, idbandeira='7')]"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "code", "source": "#Obtendo dados da tabela de compras entregas e criar a tabela tempor\u00e1ria\ndfCompraEntrega = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('compraentrega.csv', 'projetoviagrupo6-donotdelete-pr-ehmgbn0j3d7dfc'))\ndfCompraEntrega.createOrReplaceTempView(\"compraentrega\")\ndfCompraEntrega.take(1)", "execution_count": 8, "outputs": [{"data": {"text/plain": "[Row(idcompraentrega='82908258', idcompra='166020553', idfreteentregatipo='17', idcompraentregastatus='VAL', identificadorfrete=None, idadministradorstatus='1', datasaida=None, dataprevisao=None, dataentrega=None, datastatus='2019-06-05 17:55:00', prazoentregamaisdisponibilidade=None, prazoestoque=None, gerencialid='16602055302', dataemissaonotafiscal=None, idtransportadora=None, codigocontratotransportadora=None, dataentregacorrigida=None, numctrc=None, idnotafiscal=None, idperiodoentrega=None, dataentregaagendada=None, idregiao='0', flag_chave_nfe='0', dataprometidaoriginal=None, idlojista='14406', flagenviadomarketplace='0', gerencialidmktp=None, prazotransportadora='0', prazocd='0', idfilial='1', origem='TD', ordemdevolucao='0', sequencialcompra='2', flagbloqueado=None, ordemvendaerp='B20139885', flagprazoentregamarcado=None, nomeautorizaretireloja=None, rgautorizaretireloja=None, enviadolojistagpa='0', datalimitesaidacd='2019-06-05 00:00:00', sequencialprocesso='2', dataordemvendaerp='2019-06-04 06:10:58', mistura='0', modalidade='1', idcompanhia=None, tiporestricao='WN', dataentregaajustada=None, idbandeira='343')]"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "code", "source": "#Obtendo dados da tabela de compras e criar a tabela tempor\u00e1ria\ndfCompra = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .load(cos.url('compra.csv', 'projetoviagrupo6-donotdelete-pr-ehmgbn0j3d7dfc'))\ndfCompra.createOrReplaceTempView(\"compra\")\ndfCompra.take(1)", "execution_count": 9, "outputs": [{"data": {"text/plain": "[Row(idcompra='165996430', idcliente='11086617', idadministradortelevenda=None, idlistadecompra=None, midia='cpc', parceiro='rtbhouse', campanha=None, palavrachave='rtbhouse', origem=None, data='2019-06-01 10:03:00', valortotalcomdesconto='387.30', valortotalcomdesconto_devido='387.30', testeab=None, flagativa='0', statusintegracao=None, ipcliente='177.67.247.195', codigopromocao=None, infocomplcodigopromocao=None, servidororigem='CARRINHO-EX12', codloja=None, idlojafisica=None, idopcaoentregaexpressa=None, flagrespostapromocao=None, idcanalvenda='SITE', datacriacaoregistro='2019-06-04 06:02:53.520', respostapromocao=None, flag_cupom='0', idenderecolojafisica=None, useragent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36', dtajusteoperacional=None, idtipopedido='1', flaggerapontos=None, dataaceiteclubeextra=None, idtipoimposto=None, cif_fob=None, pedidoexterno=None, sequencial='1', flagcomprasige=None, flagaprovado='1', dataaprovacao='2019-06-04 06:02:53.773', idcomprastatusproxy='5', idunidadenegocio='5', priorizado=None, flagpreautorizado=None, flagpreonline='0', operador=None, idciaafiliacao='1', idbandeira='49')]"}, "execution_count": 9, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Identificar o per\u00edodo de dados existente na base"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT min(cast(CP.data as date)) \\\n                 ,max(cast(CP.data as date)) \\\n             FROM compra CP\\\n                 ,compraentrega CE\\\n                 ,compraentregasku CES\\\n            where CP.idcompra = CE.idcompra \\\n              and CE.idcompraentrega = CES.idcompraentrega \\\n             ;\").show()", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20210530160935-0000\nKERNEL_ID = 41b8ea04-c4d9-408b-85ec-ecf0a2759553\n", "name": "stdout"}, {"output_type": "error", "ename": "AnalysisException", "evalue": "Table or view not found: compra; line 1 pos 97;\n'Project [unresolvedalias('min(cast('CP.data as date)), None), unresolvedalias('max(cast('CP.data as date)), None)]\n+- 'Filter (('CP.idcompra = 'CE.idcompra) AND ('CE.idcompraentrega = 'CES.idcompraentrega))\n   +- 'Join Inner\n      :- 'Join Inner\n      :  :- 'SubqueryAlias CP\n      :  :  +- 'UnresolvedRelation [compra]\n      :  +- 'SubqueryAlias CE\n      :     +- 'UnresolvedRelation [compraentrega]\n      +- 'SubqueryAlias CES\n         +- 'UnresolvedRelation [compraentregasku]\n", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-1-246ff901d029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT min(cast(CP.data as date))                  ,max(cast(CP.data as date))              FROM compra CP                 ,compraentrega CE                 ,compraentregasku CES            where CP.idcompra = CE.idcompra               and CE.idcompraentrega = CES.idcompraentrega              ;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m/opt/ibm/conda/miniconda/lib/python/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \"\"\"\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/ibm/conda/miniconda/lib/python/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1310\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/ibm/conda/miniconda/lib/python/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/opt/ibm/conda/miniconda/lib/python/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n", "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: compra; line 1 pos 97;\n'Project [unresolvedalias('min(cast('CP.data as date)), None), unresolvedalias('max(cast('CP.data as date)), None)]\n+- 'Filter (('CP.idcompra = 'CE.idcompra) AND ('CE.idcompraentrega = 'CES.idcompraentrega))\n   +- 'Join Inner\n      :- 'Join Inner\n      :  :- 'SubqueryAlias CP\n      :  :  +- 'UnresolvedRelation [compra]\n      :  +- 'SubqueryAlias CE\n      :     +- 'UnresolvedRelation [compraentrega]\n      +- 'SubqueryAlias CES\n         +- 'UnresolvedRelation [compraentregasku]\n"]}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Relacionando as bases tempor\u00e1rias para o per\u00edodo de COMPRAS realizadas em at\u00e9 60 dias\n#### Observa\u00e7\u00f5es:\n##### 1) A base de COMPRA se encontra com informa\u00e7\u00f5es at\u00e9 o dia 30-04-2021 conforme visto no passo antes.\n##### 2) Para uma base produtiva \"online\" \u00e9 interessante fazer a seguinte substitui\u00e7\u00e3o no c\u00f3digo:\n##### - DE: and cast(CP.data as date) >= cast('2021-04-30' as date) - 60\n##### - PARA: and cast(CP.data as date) >= current_date() - 60\n##### 3) Foi considerado para este MVP somente os seguintes sellers:\n##### - idlojista in ('10012','37450','92893','80333','64189')\n## Aten\u00e7\u00e3o: recomendado que se tire tal filtro para um ambiente produtivo deste notebook)"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT distinct CS.idskureferencia \\\n                 ,L.idlojista, L.estado \\\n                 ,cast(CS.valorfrete as decimal(15,2)) \\\n                 ,cast(CS.valorvendaunidadesemdesconto as decimal(15,2)) as valor \\\n             FROM compra CP\\\n                 ,compraentrega CE\\\n                 ,compraentregasku CS\\\n                 ,Lojista L\\\n            where CP.idcompra = CE.idcompra \\\n              and CE.idcompraentrega = CS.idcompraentrega \\\n              and L.idlojista = CE.idlojista\\\n              and cast(CP.data as date) >= cast('2021-04-30' as date) - 60 \\\n             ;\").show()", "execution_count": 16, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------------+---------+------+----------+-------+\n|idskureferencia|idlojista|estado|valorfrete|  valor|\n+---------------+---------+------+----------+-------+\n|       14245852|    31065|    SP|      9.38|  99.99|\n|     1509924831|    11121|    RS|     59.90| 139.90|\n|       15398757|    13728|    SP|     21.89| 114.90|\n|       14803748|    35430|    SP|      6.38| 146.90|\n|       13619054|    31534|    PR|     53.50| 239.90|\n|     1510681709|    56358|    ES|      2.61|   3.32|\n|     1500199983|    19937|    RS|     69.90|1069.00|\n|     1508520142|    12231|    PR|     16.33|  34.99|\n|     1511459552|    12231|    PR|      0.00|  89.90|\n|       12735627|    10172|    SP|      5.70|   4.75|\n|     1500892287|    36642|    SP|     48.58|1999.00|\n|     1509342376|    32365|    ES|     54.18| 209.00|\n|     1501157230|    36642|    SP|     28.23| 139.99|\n|     1509515865|    44362|    MG|      7.32|  86.90|\n|       11437388|    26255|    RJ|     -6.11| -39.99|\n|     1502297692|    12231|    PR|    -11.65| -27.00|\n|     1505061686|    20274|    MG|      0.00|1618.90|\n|     1512668960|    59828|    SC|     15.36|  74.90|\n|     1502799461|    33791|    SP|      8.10|  89.00|\n|        3276042|    24506|    PR|    128.47|2599.00|\n+---------------+---------+------+----------+-------+\nonly showing top 20 rows\n\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "**Juntando as tabelas de compras para obter os valores de frete e pre\u00e7o praticado para obter os valores finais depois**\nA id\u00e9ia \u00e9 usar o pre\u00e7o do frete como indicador para o seller tamb\u00e9m"}, {"metadata": {}, "cell_type": "code", "source": "dtSKUSvendidos = spark.sql(\"SELECT distinct CS.idskureferencia \\\n                 ,L.idlojista, L.estado \\\n                 ,cast(CS.valorfrete as decimal(15,2)) \\\n                 ,cast(CS.valorvendaunidadesemdesconto as decimal(15,2)) as valor \\\n             FROM compra CP\\\n                 ,compraentrega CE\\\n                 ,compraentregasku CS\\\n                 ,Lojista L\\\n            where CP.idcompra = CE.idcompra \\\n              and CE.idcompraentrega = CS.idcompraentrega \\\n              and L.idlojista = CE.idlojista\\\n              and cast(CP.data as date) >= cast('2021-04-30' as date) - 60 \\\n             ;\")\ndtSKUSvendidos.createOrReplaceTempView(\"SKUSvendidos\")", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Juntando as tabelas criadas pre\u00e7o de cat\u00e1logo e pre\u00e7o praticado para ter uma \u00fanica tabela \n## Aten\u00e7\u00e3o: Para utiliza\u00e7\u00e3o em ambiente produtivoa, precisa retirar o filtro dos sellers selecionados para o MVP"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT idlojista, estado, idskureferencia \\\n                 ,valor as precovenda, valorfrete \\\n             FROM SKUSvendidos \\\n           union all  \\\n           SELECT idlojista, estado, idskureferencia \\\n                 ,precovenda, 0 as valorfrete \\\n             FROM SKUS SK \\\n             where idlojista IN (10012,37450,92893,80333,64189) \\\n              and idskureferencia not in ( select idskureferencia \\\n             from SKUSvendidos SV where SK.idskureferencia = SV.idskureferencia) \\\n             ;\").show()", "execution_count": 18, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+------+---------------+----------+----------+\n|idlojista|estado|idskureferencia|precovenda|valorfrete|\n+---------+------+---------------+----------+----------+\n|    31065|    SP|       14245852|     99.99|      9.38|\n|    11121|    RS|     1509924831|    139.90|     59.90|\n|    13728|    SP|       15398757|    114.90|     21.89|\n|    35430|    SP|       14803748|    146.90|      6.38|\n|    31534|    PR|       13619054|    239.90|     53.50|\n|    56358|    ES|     1510681709|      3.32|      2.61|\n|    32252|    RS|       14502946|    219.90|     49.47|\n|    36913|    GO|       11704305|    139.99|      7.50|\n|    19937|    RS|     1500199983|   1069.00|     69.90|\n|    12231|    PR|     1508520142|     34.99|     16.33|\n|    12231|    PR|     1511459552|     89.90|      0.00|\n|    10172|    SP|       12735627|      4.75|      5.70|\n|    36642|    SP|     1500892287|   1999.00|     48.58|\n|    32365|    ES|     1509342376|    209.00|     54.18|\n|    36642|    SP|     1501157230|    139.99|     28.23|\n|    14610|    SP|     1500215101|    198.00|     75.33|\n|    30971|    SC|     1501559339|    269.90|      5.04|\n|    31001|    ES|     1504366760|   2499.00|     29.00|\n|    14551|    PR|       11813171|    557.90|     34.27|\n|    15950|    PR|     1500421902|    119.00|     20.00|\n+---------+------+---------------+----------+----------+\nonly showing top 20 rows\n\n"}]}, {"metadata": {}, "cell_type": "code", "source": "#criando uma tabela tempor\u00e1ria para gerar os valores depois\ndfvaloresSKUs = spark.sql(\"SELECT idlojista, estado, idskureferencia \\\n                 ,valor as precovenda, valorfrete \\\n             FROM SKUSvendidos \\\n           union all  \\\n           SELECT idlojista, estado, idskureferencia \\\n                 ,precovenda, 0 as valorfrete \\\n             FROM SKUS SK \\\n             where idlojista IN (10012,37450,92893,80333,64189) \\\n              and idskureferencia not in ( select idskureferencia \\\n             from SKUSvendidos SV where SK.idskureferencia = SV.idskureferencia) \\\n             ;\")\ndfvaloresSKUs.createOrReplaceTempView(\"valoresSKUs\")", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Obter os valores m\u00e9dio, m\u00ednimo e m\u00e1ximo"}, {"metadata": {}, "cell_type": "code", "source": "spark.sql(\"SELECT estado, idskureferencia \\\n                 ,min(ABS(precovenda)) as minVrVenda \\\n                 ,max(ABS(precovenda)) as maxVrVenda \\\n                 ,mean(ABS(precovenda)) as mediaVrVenda \\\n                 ,min(ABS(valorfrete)) as minVrFrete \\\n                 ,max(ABS(valorfrete)) as maxVrFrete \\\n                 ,mean(ABS(valorfrete)) as mediaVrFrete\\\n             FROM valoresSKUs \\\n             group by estado, idskureferencia \\\n             ;\").show()", "execution_count": 20, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------+---------------+----------+----------+------------+----------+----------+------------+\n|estado|idskureferencia|minVrVenda|maxVrVenda|mediaVrVenda|minVrFrete|maxVrFrete|mediaVrFrete|\n+------+---------------+----------+----------+------------+----------+----------+------------+\n|    PR|       13618740|    239.90|    239.90|  239.900000|     23.10|    157.13|   64.160465|\n|    SP|        7496708|    184.90|    184.90|  184.900000|     61.42|     61.42|   61.420000|\n|    SP|     1509840277|   1549.00|   1549.00| 1549.000000|     30.62|     63.36|   46.990000|\n|    PR|     1504162920|   1899.99|   1899.99| 1899.990000|     22.00|     84.31|   48.560000|\n|    SC|        6804778|     35.88|     35.88|   35.880000|     16.09|     16.09|   16.090000|\n|    SP|     1505205640|    209.00|    209.00|  209.000000|     22.52|     22.52|   22.520000|\n|    ES|     1506693425|    428.00|    449.00|  442.100000|     39.41|     87.71|   52.944000|\n|    PR|     1510298611|     72.88|     74.90|   74.226667|      9.08|     21.56|   14.186667|\n|    ES|     1510598213|   1221.00|   1221.00| 1221.000000|     79.99|     79.99|   79.990000|\n|    ES|     1504325760|    549.00|    549.00|  549.000000|     51.28|     73.29|   61.340000|\n|    SC|       15427061|    774.00|    774.00|  774.000000|     49.00|    139.00|   95.666667|\n|    MG|     1508521137|   2789.90|   2789.90| 2789.900000|     96.28|    159.52|  116.953333|\n|    PR|     1511562717|     79.90|     79.90|   79.900000|     15.73|     15.73|   15.730000|\n|    PR|       14758196|   1129.00|   1189.00| 1141.307692|     32.25|     80.46|   47.853077|\n|    PR|       13721381|   1799.00|   2049.00| 1865.962963|     40.07|    128.45|   66.941111|\n|    MG|     1503139244|    249.00|    279.00|  254.213514|     11.72|     76.45|   33.870000|\n|    PR|       15118186|   1129.00|   1199.00| 1146.857143|     26.28|    120.93|   53.098095|\n|    PR|       15008306|   1279.00|   1279.00| 1279.000000|    400.00|    400.00|  400.000000|\n|    MG|     1504827781|    129.00|    129.00|  129.000000|      0.00|     15.90|    7.950000|\n|    RS|     1509472457|   1099.00|   1099.00| 1099.000000|     54.57|    176.37|  106.464000|\n+------+---------------+----------+----------+------------+----------+----------+------------+\nonly showing top 20 rows\n\n"}]}, {"metadata": {}, "cell_type": "code", "source": "# criando um dataframe da tabela gerada para gravar em disco\ndfTabelaFinal = spark.sql(\"SELECT estado, idskureferencia \\\n                 ,min(ABS(precovenda)) as minVrVenda \\\n                 ,max(ABS(precovenda)) as maxVrVenda \\\n                 ,mean(ABS(precovenda)) as mediaVrVenda \\\n                 ,min(ABS(valorfrete)) as minVrFrete \\\n                 ,max(ABS(valorfrete)) as maxVrFrete \\\n                 ,mean(ABS(valorfrete)) as mediaVrFrete\\\n             FROM valoresSKUs \\\n             group by estado, idskureferencia \\\n             ;\")", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Os pr\u00f3xmos passos \u00e9 para grava\u00e7\u00e3o do reultado obtido em uma tabela (arquivo) em disco"}, {"metadata": {}, "cell_type": "markdown", "source": "### Listando as pastas que est\u00e3o na raiz do projeto"}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 21, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\u001b[0m\u001b[01;34mconda\u001b[0m/  \u001b[01;34mlogs\u001b[0m/  \u001b[01;34mspark-events\u001b[0m/  \u001b[01;34muser-libs\u001b[0m/\r\n"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Criando uma pasta tempor\u00e1ria: tmp"}, {"metadata": {}, "cell_type": "code", "source": "mkdir tmp", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 23, "outputs": [{"name": "stdout", "output_type": "stream", "text": "\u001b[0m\u001b[01;34mconda\u001b[0m/  \u001b[01;34mlogs\u001b[0m/  \u001b[01;34mspark-events\u001b[0m/  \u001b[01;34mtmp\u001b[0m/  \u001b[01;34muser-libs\u001b[0m/\r\n"}]}, {"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 24, "outputs": [{"data": {"text/plain": "'/home/spark/shared'"}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}]}, {"metadata": {}, "cell_type": "code", "source": "dfTabelaFinal.repartition(1).write.mode(\"overwrite\").parquet(\"/home/spark/shared/tmp/variacao_preco.parquet\")", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dfTabelaFinal.repartition(1).write.mode(\"overwrite\").csv('/home/spark/shared/tmp/variacao_preco.csv')", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cd /home/spark/shared/tmp", "execution_count": 27, "outputs": [{"name": "stdout", "output_type": "stream", "text": "/home/spark/shared/tmp\n"}]}, {"metadata": {}, "cell_type": "code", "source": "ls variacao_preco.parquet/", "execution_count": 29, "outputs": [{"name": "stdout", "output_type": "stream", "text": "part-00000-55badd35-9ca5-4fe7-810a-d91f70baf211-c000.snappy.parquet  _SUCCESS\r\n"}]}, {"metadata": {}, "cell_type": "code", "source": "ls variacao_preco.csv/", "execution_count": 30, "outputs": [{"name": "stdout", "output_type": "stream", "text": "part-00000-ccec852c-305e-456c-a653-58d1917ae35b-c000.csv  _SUCCESS\r\n"}]}, {"metadata": {}, "cell_type": "code", "source": "#Credenciais para grava\u00e7\u00e3o em disco e disponibilizar nos ativos\ncredentials_1 = {\n    'IAM_SERVICE_ID': 'iam-ServiceId-f8ddc357-a261-42a2-a6f2-44ac38d6cc50',\n    'IBM_API_KEY_ID': '5y97tXSIMk-o11IIlG-qhORjxg4zQ6yFprxqB54ntyX9',\n    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/oidc/token',\n    'BUCKET': 'projetoviagrupo6-donotdelete-pr-ehmgbn0j3d7dfc',\n}\n\ncgsClient = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id = credentials_1['IBM_API_KEY_ID'],\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')", "execution_count": 33, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cgsClient.upload_file(Filename='variacao_preco.parquet/part-00000-55badd35-9ca5-4fe7-810a-d91f70baf211-c000.snappy.parquet',Bucket=credentials_1['BUCKET'],Key='variacao_preco.parquet')", "execution_count": 35, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "cgsClient.upload_file(Filename='variacao_preco.csv/part-00000-ccec852c-305e-456c-a653-58d1917ae35b-c000.csv',Bucket=credentials_1['BUCKET'],Key='variacao_preco.csv')", "execution_count": 36, "outputs": []}], "metadata": {"kernelspec": {"name": "python37", "display_name": "Python 3.7 with Spark", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.7.10", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4, "nbformat_minor": 1}